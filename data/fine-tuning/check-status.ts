import fs from 'fs';
import path from 'path';
import { openai } from '../../src/config/index';
import { Logger } from '../../src/utils/logger';

/**
 * Fine-tuning Status Checker
 * Monitors OpenAI fine-tuning job progress and displays metrics
 * Part of Branch 4: Fine-tuning implementation
 */
class StatusChecker {
  private readonly jobsFilePath: string;

  constructor() {
    this.jobsFilePath = path.join(__dirname, 'fine-tuning-jobs.json');
  }

  /**
   * Load job information following workshop file patterns
   */
  private loadJobInfo(): any {
    if (!fs.existsSync(this.jobsFilePath)) {
      throw new Error('No fine-tuning jobs found. Run: npm run fine-tuning:train');
    }

    const jobData = fs.readFileSync(this.jobsFilePath, 'utf8');
    return JSON.parse(jobData);
  }

  /**
   * Get detailed job status from OpenAI
   */
  private async getJobStatus(jobId: string): Promise<any> {
    try {
      const job = await openai.fineTuning.jobs.retrieve(jobId);
      return job;
    } catch (error) {
      Logger.error('âŒ Failed to retrieve job status:', error);
      throw error;
    }
  }

  /**
   * Format status display following workshop logging patterns
   */
  private displayStatus(job: any, localJobInfo: any): void {
    Logger.info('ğŸ¯ Workshop: Progressive Product Semantic Search - Branch 4');
    Logger.info(`ğŸ“Š Fine-tuning Status Check`);
    Logger.info(`ğŸ†” Job ID: ${job.id}`);
    Logger.info(`â±ï¸ Status: ${job.status}`);
    Logger.info(`ğŸ“ Training file: ${job.training_file}`);
    Logger.info(`ğŸ¤– Base model: ${job.model}`);
    
    if (job.fine_tuned_model) {
      Logger.info(`âœ… Fine-tuned model: ${job.fine_tuned_model}`);
    }

    // Display metrics if available (cost optimization tracking)
    if (job.trained_tokens) {
      Logger.info(`ğŸ“Š Trained tokens: ${job.trained_tokens.toLocaleString()}`);
    }

    if (job.hyperparameters) {
      Logger.info(`ğŸ”§ Hyperparameters:`);
      Logger.info(`   Epochs: ${job.hyperparameters.n_epochs}`);
      Logger.info(`   Batch size: ${job.hyperparameters.batch_size}`);
      Logger.info(`   Learning rate: ${job.hyperparameters.learning_rate_multiplier}`);
    }

    // Workshop context
    Logger.info(`ğŸ—ï¸ Created: ${localJobInfo.createdAt}`);
    Logger.info(`ğŸ¯ Purpose: ${localJobInfo.purpose}`);
  }

  /**
   * Update local job info with latest status
   */
  private updateJobInfo(job: any, localJobInfo: any): void {
    const updatedInfo = {
      ...localJobInfo,
      lastChecked: new Date().toISOString(),
      currentStatus: job.status,
      fineTunedModel: job.fine_tuned_model || null,
      trainedTokens: job.trained_tokens || null,
      estimatedFinish: job.estimated_finish || null
    };

    fs.writeFileSync(this.jobsFilePath, JSON.stringify(updatedInfo, null, 2));
    Logger.info('ğŸ“ Job info updated');
  }

  /**
   * Check training status following workshop patterns
   */
  async checkStatus(): Promise<void> {
    try {
      Logger.info('ğŸ” Checking fine-tuning job status...');

      // Load local job info
      const localJobInfo = this.loadJobInfo();
      
      // Get current status from OpenAI
      const job = await this.getJobStatus(localJobInfo.jobId);

      // Display status with workshop context
      this.displayStatus(job, localJobInfo);

      // Update local tracking
      this.updateJobInfo(job, localJobInfo);

      // Status-specific messaging following workshop patterns
      console.log('\nğŸ“Š Current Status:', job.status);
      
      switch (job.status) {
        case 'validating_files':
          console.log('ğŸ” Validating training data format and content...');
          console.log('â³ This usually takes 1-2 minutes');
          break;
          
        case 'queued':
          console.log('ğŸ“‹ Job is queued for processing...');
          console.log('â³ Waiting for available compute resources');
          break;
          
        case 'running':
          console.log('ğŸš€ Training in progress!');
          console.log('â³ Expected completion: 10-20 minutes');
          if (job.trained_tokens) {
            console.log(`ğŸ“Š Progress: ${job.trained_tokens.toLocaleString()} tokens processed`);
          }
          break;
          
        case 'succeeded':
          console.log('âœ… Training completed successfully!');
          console.log(`ğŸ¤– Fine-tuned model: ${job.fine_tuned_model}`);
          console.log('ğŸ“‹ Next step: npm run fine-tuning:evaluate');
          break;
          
        case 'failed':
          console.log('âŒ Training failed');
          if (job.error) {
            console.log(`ğŸ” Error: ${job.error.message}`);
          }
          console.log('ğŸ› ï¸ Check your training data format');
          break;
          
        case 'cancelled':
          console.log('â¹ï¸ Training was cancelled');
          break;
          
        default:
          console.log(`â„¹ï¸ Status: ${job.status}`);
      }

      // Workshop cost tracking
      if (job.trained_tokens) {
        const estimatedCost = (job.trained_tokens / 1000000) * 8; // $8 per 1M tokens for gpt-4o-mini fine-tuning
        console.log(`ğŸ’° Estimated cost: ~$${estimatedCost.toFixed(4)} (workshop cost optimization)`);
      }

    } catch (error) {
      Logger.error('âŒ Status check failed:', error);
      console.error('\nâŒ Status check failed!');
      console.error('ğŸ” Error details:', error instanceof Error ? error.message : error);
      console.error('\nğŸ› ï¸ Troubleshooting:');
      console.error('   1. Verify job was created: npm run fine-tuning:train');
      console.error('   2. Check OpenAI API connectivity');
      console.error('   3. Verify fine-tuning-jobs.json exists');
      process.exit(1);
    }
  }
}

// Execute if run directly
if (require.main === module) {
  const checker = new StatusChecker();
  checker.checkStatus().catch(console.error);
}

export { StatusChecker };